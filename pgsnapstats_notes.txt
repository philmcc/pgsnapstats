 

TODO

	ADD
		pg_stat_activity
		pg_stat_replication
		pg_stat_database_conflicts

	Deal with the various extensions being there or not and still get the most data possible.
	List views required
	Code Views
	Code testing version ans put it all in a 9.2 function
	Work out how to connect to local instances with python

Alow specifying range of snap and let views/reports report on either 1 or an aggrigate of multiple snaps.

Alow taking snapshots manually for a db to capture specific events

--------------------------------------
Report List

Snapstats db summary
DB Summary
Snapshot Summary
Transactions - commits and rollbacks (for each snap)
DB size - (at each snap)
Recovery conflicts
Instance activity - walwrite and speed
	Specific wal written
OS resources per snap and total
Memory Useage
Disk useage
Long taransactions
Noitable tables
	heavily updates
		accessed
	low density tables
	fragmented tables
checkpoint activity
autovacuum activity
Basic stats
IO stats

Querrys
functions
statements
Lock conflicts
Replication activity

Settings
Schema Info
--------------------------------------

select cast(substring(version(), 'PostgreSQL ([0-9]*).') as int) into version_major;
select cast(substring(version(), 'PostgreSQL [0-9]*.([0-9]*).') as int) into version_minor;



Am I getting exactly what is produced in the database?
	9.2
	pg_stat_bgwriter - YES
	pg_stat_database - YES
	pg_stat_user_tables - YES
	pg_stat_user_indexes - YES	
	pg_statio_all_indexes - YES
	pg_statio_all_sequences - YES
	pg_stat_user_functions - YES
	
	pg_stat_activity  - NO 
		The pg_stat_activity view will have one row per server process, showing information related to the current activity of that process.
			Note: The waiting and state columns are independent. If a backend is in the active state, it may or may not be waiting. If the state is active and waiting is true, it means that a query is being executed, but is being blocked by a lock somewhere in the system.
	pg_stat_replication - NO
		The pg_stat_replication view will contain one row per WAL sender process, showing statistics about replication to that sender's connected standby server. Only directly connected standbys are listed; no information is available about downstream standby servers.
	pg_stat_database_conflicts - NO (Would only be required on standby servers)
		The pg_stat_database_conflicts view will contain one row per database, showing database-wide statistics about query cancels occurring due to conflicts with recovery on standby servers. This view will only contain information on standby servers, since conflicts do not occur on master servers.




How will it remain flexible enough to change when a new version introduces new data?

What exactly do I want to generate results wise to presentto the front end?

Can I make pulling the data and inserting back more generic?

Can I compare snapshot periods?
snap 1-3 vs snap 6-8 for example

Can I store plans and have them visable from the front end

In front end - query is clickable to expand and expose plan


		db is pgsnapstats - tables do not need th eprefix
		Views should start with v_
In set_up_db, do I really want to drop is already exists on create. how about a seperate function to clean and drop before running the create db if a flag is specified

Replication data
	lag
	wal
	Map - where does the server sit in the cluster which master/slaves does it have.
		Can we see the stats for the whole cluster? Just slaves? Specific groups?
	Snaps wont match perfectly - Can that be overcame with regards to agregating a cluster together?

Log to text files specific to each databases name

Sequence

Get list of dbs
spawn x threads doing:
	Into db
	which version
		execute that versions function
		get basic data
		check stat statements exits
			get that data if so
		check that stat_plans exists
			get that data if so
		Is server involved with replication
			Get replication data if so




Data to represent
******http://pgstatsinfo.projects.pgfoundry.org/files/report_sample.txt	
http://www.pafumi.net/AWR%20Reports.html
http://learntestingtools.com/understand-performance-of-oracle-database-using-awr-report/

	Snapshot Details
	Load Profile
	DB Time
		Reads (Logical & Physical)
		Transactions (and Rollbacks) & Executes
		SQL Ordered by Elapsed Time:
		SQL Ordered by CUP Time:
		SQL Statistics Section
This section displays top SQL, ordered by important SQL execution metrics.
- SQL Ordered by Elapsed Time: Includes SQL statements that took significant execution time during processing.
- SQL Ordered by CPU Time: Includes SQL statements that consumed significant CPU time during its processing.
- SQL Ordered by Gets: These SQLs performed a high number of logical reads while retrieving data.
- SQL Ordered by Reads: These SQLs performed a high number of physical disk reads while retrieving data.
- SQL Ordered by Executions: 
- SQL Ordered by Parse Calls: These SQLs experienced a high number of reparsing operations.
- SQL Ordered by Sharable Memory: Includes SQL statements cursors which consumed a large amount of SGA shared pool memory.
- SQL Ordered by Version Count: These SQLs have a large number of versions in shared pool for some reason.
- Complete List of SQL Text: 


Segment Statistics Section:
This report section provides details about hot segments using the following criteria:
- Segments by Logical Reads: Includes top segments which experienced high number of logical reads.
- Segments by Physical Reads: Includes top segments which experienced high number of disk physical reads.
- Segments by Row Lock Waits: Includes segments that had a large number of row locks on their data.
- Segments by ITL Waits: Includes segments that had a large contention for Interested Transaction List (ITL). The contention for ITL can be reduced by increasing INITRANS storage parameter of the table.
- Segments by Buffer Busy Waits: These segments have the largest number of buffer waits caused by their data blocks.














Research topics

PostgreSQL Shared Memory
	buffer cache
	
CROSS JOIN
Join types
	
Postgres High Performance
	http://www.amazon.com/gp/product/184951030X/ref=as_li_qf_sp_asin_tl?ie=UTF8&tag=mypred-20&linkCode=as2&camp=1789&creative=9325&creativeASIN=184951030X
	
pg_stat_plans - automatically pull plans into snap db?

optimizing
http://www.craigkerstiens.com/2013/01/10/more-on-postgres-performance/

High Performance PostgreSQL
http://www.amazon.com/dp/184951030X?tag=mypred-20


-----------------------------
-----------------------------
To do on pgsnapstats - for V0.2



check that pg stats statements is installed
	Install if not?



add replication information

remove previous queries from snap
************	could I just reset stats after each snap*************
At beginning of snap store stats last reset time 
After collect pg_stat_statements get
	reset stats
	select pg_stat_reset();
	select pg_stat_statements_reset();
Should I put a flag in databases table to say reset stats and only reset if set?
Add in stats reset Time to snap table and snap insert
	

pg_stat_activity
pg_stat_replication
pg_stat_database_conflicts


	
Auto discovery of databases
Auto discovery of slaves

add explain plans to statements (pg_stat_plans)

DONE IN CODE - NOT RAN --
change index pgsnapstats_statements_pk" PRIMARY KEY, btree (snapid, user_name, query)
to be just pgsnapstats_statements_pk" PRIMARY KEY, btree (snapid, user_name, query)

DONE IN CODE - NOT RAN --
add timezone to pgsnapstats_snap time fields

DONE - add end time to snap

FIELD NOT AVAILABLE - add query id to pgsnapstats_statements

-----------------------------

These queries get data from the latest snap but if stats are reset at each snap then this will not get all data

Report that gets top queries per db by total time.

create view latest_top_queries_by_total_time as
SELECT (st.total_time / 1000 / 60) as total_minutes, 
(st.total_time/st.calls) as average_time_ms, 
st.query,
sn.dbname,
st.snapid
from pgsnapstats_statements st, pgsnapstats_snap sn,
(select dbname, max(snapid) id from pgsnapstats_snap group by dbname) latest
where st.snapid = sn.snapid
and sn.snapid = latest.id
ORDER BY 1 DESC; 

Report that gets top queries per db by avg time for each execution.

create view latest_top_queries_by_avg_time as
SELECT (st.total_time / 1000 / 60) as total_minutes, 
(st.total_time/st.calls) as average_time_ms, 
st.query,
sn.dbname,
st.snapid
from pgsnapstats_statements st, pgsnapstats_snap sn,
(select dbname, max(snapid) id from pgsnapstats_snap group by dbname) latest
where st.snapid = sn.snapid
and sn.snapid = latest.id
ORDER BY 2 DESC; 

Examine execution plans for potential improvements/savings

reports:
	seq scans on tables over a certain size - (index candidates)
	queries where most of returned rows are removed - (composite indexes candidates)
		i.e. - Rows Removed by Filter: 14


statements returned per snap order by dbname then snapid:

select st.snapid, sn.dbname, count(st.query) 
from pgsnapstats_statements st, pgsnapstats_snap sn  
where st.snapid = sn.snapid 
group by st.snapid, dbname 
order by sn.dbname, st.snapid desc;


To generate a list of your tables in your database with the largest ones first and the percentage of time which they use an index you can run:
SELECT relname, 100 * idx_scan / (seq_scan + idx_scan) percent_of_times_index_used, n_live_tup rows_in_table FROM pg_stat_user_tables WHERE seq_scan + idx_scan > 0 ORDER BY n_live_tup DESC;

SELECT latest.dbname, t.snapid, t.table_name, 100 * t.idx_scan / (t.seq_scan + t.idx_scan) percent_of_times_index_used, t.n_live_tup rows_in_table 
FROM pgsnapstats_tables t,
(select dbname, max(snapid) id from pgsnapstats_snap group by dbname) latest
WHERE t.seq_scan + t.idx_scan > 0
and t.snapid = latest.id 
ORDER BY t.n_live_tup DESC;


SELECT latest.dbname, t.snapid, t.table_name, 100 * t.idx_scan / (t.seq_scan + t.idx_scan) percent_of_times_index_used, t.n_live_tup rows_in_table 
FROM pgsnapstats_tables t,
(select dbname, max(snapid) id from pgsnapstats_snap group by dbname) latest
WHERE t.snapid = latest.id 
ORDER BY t.n_live_tup DESC;




An SQL query that computes buffer hits percentages looks roughly like this:

SELECT sum(heap_blks_read) / sum(heap_blks_hit) * 100 as TABLE, \
    sum(idx_blks_read) / sum(idx_blks_hit) * 100 as INDEX, \
    sum(toast_blks_read) / sum(toast_blks_hit) * 100 as TOAST, \
    sum(tidx_blks_read) / sum(tidx_blks_hit) as TOASTIND \
    FROM pg_statio_user_tables) tables, \
    (SELECT sum(blks_read) / sum(blks_hit) * 100 as SEQUENCE
    FROM pg_statio_user_sequences) sequences




-------------------------------
-------------------------------

Thoughts / ideas

Capture long running queries at time of snap:
SELECT datname,pid,query_start, now() - query_start as runtime,waiting, state FROM pg_stat_activity order by query_start asc;

